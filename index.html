<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>CE888 2017</title>

    <!-- Bootstrap -->
    <link href="./bootstrap/css/bootstrap.cr.css" rel="stylesheet">
    <link href="./ce888.css" rel="stylesheet">
    <link rel="shortcut icon" href="graphics/favicon.ico">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
<nav class="navbar navbar-default navbar-fixed-top">

     
      <div class="container">
       <a href="#data-science-and-decision-making" class="navbar-brand">CE888</a>
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
           
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">


            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="Lectures">Lectures <span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="Lectures">
                
                <li class="divider"></li>
                <li><a href="#lec1">Lecture 1</a></li>
                <li><a href="#lec2">Lecture 2</a></li>
                <li><a href="#lec3">Lecture 3</a></li>
                <li><a href="#lec4">Lecture 4</a></li>
                <li><a href="#lec5">Lecture 5</a></li>
                <li><a href="#lec6">Lecture 6</a></li>
                <li><a href="#lec7">Lecture 7</a></li>
                <li><a href="#lec8">Lecture 8</a></li>
                <li><a href="#lec9">Lecture 9</a></li>
                <li><a href="#lec10">Lecture 10</a></li>
    
              </ul>
            </li>

            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="Labs">Labs <span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="Labs">
                
                <li class="divider"></li>
                <li><a href="#lab1">Lab 1</a></li>
                <li><a href="#lab2">Lab 2</a></li>
                <li><a href="#lab3">Lab 3</a></li>
                <li><a href="#lab4">Lab 4</a></li>
                <li><a href="#lab5">Lab 5</a></li>
                <li><a href="#lab6">Lab 6</a></li>
                <li><a href="#lab7">Lab 7</a></li>
                <li><a href="#lab8">Lab 8</a></li>
                <li><a href="#lab9">Lab 9</a></li>
                <li><a href="#lab10">Lab 10</a></li>
    
              </ul>
            </li>

            <li><a href="#assignment-suggestions">Assignment Suggestions</a></li>

            
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
    <div class="row">
    
     
      <div class="span9">
            <h1 id="data-science-and-decision-making">Data Science and Decision Making</h1>
<h3 id="overall">Overall</h3>
<p>This is a new module on Data Science and Decision Making - we will examine most aspects of modern data science and try to create a fully-fledged end-to-end data science app. The module outline can be found <a href="https://www.essex.ac.uk/modules/Default.aspx?coursecode=CE888&amp;year=17">here</a> - but it is still subject to minor changes. The lecture notes and lab scripts for this course will be made available and further developed during the module.</p>
<p>This is a very hands-on module, where the goal is to give you sufficient breadth and depth to work as an independent data scientist. The course is assessed solely through coursework.</p>
<h3 id="lectures">Lectures</h3>
<p>Lectures take place on <strong>Tuesday 09:00-11:00 at Room 6.345</strong>.</p>
<p><a id="lec1"></a></p>
<ol style="list-style-type: decimal">
<li><a href="./slides/01-Introduction-slides.pdf">Lecture 1: Introduction</a>, <a href="./slides/01-Introduction-handouts.pdf">Handouts</a></li>
</ol>
<p><a id="lec2"></a></p>
<ol start="2" style="list-style-type: decimal">
<li><a href="./slides/02-Stats-Slides.pdf">Lecture 2: Summary and resampling statistics</a>, <a href="./slides/02-Stats-handouts.pdf">Handouts</a></li>
</ol>
<p><a id="lec3"></a></p>
<ol start="3" style="list-style-type: decimal">
<li><a href="./slides/03-Modelling-slides.pdf">Lecture 3: Predictive modelling</a>, <a href="./slides/03-Modelling-handouts.pdf">Handouts</a></li>
</ol>
<p><a id="lec4"></a></p>
<ol start="4" style="list-style-type: decimal">
<li><a href="./slides/04-Bandits-slides.pdf">Lecture 4: Bandits</a>, <a href="./slides/04-Bandits-handouts.pdf">Handouts</a></li>
</ol>
<p><a id="lec5"></a></p>
<ol start="5" style="list-style-type: decimal">
<li><a href="./slides/05-Recommender-slides.pdf">Lecture 5: Recommender systems</a>, <a href="./slides/05-Recommender-handouts.pdf">Handouts</a></li>
</ol>
<p><a id="lec6"></a></p>
<ol start="5" style="list-style-type: decimal">
<li><a href="./slides/06-Exploration-slides.pdf">Lecture 6: Data exploration</a>, <a href="./slides/06-Exploration-handouts.pdf">Handouts</a></li>
</ol>
<h3 id="labs">Labs</h3>
<p>Labs are every <strong>Fridays 15:00-18:00, CES Lab 3</strong>. Labs are assessed and they should be completed either in class or later on.</p>
<p>Please download the lab Virtual Machine from here: <a href="https://docs.google.com/uc?id=0B_kDfEzMuWD6ZGJFU1VfeEY3TnM&amp;export=download">MLVM Virtual Machine</a></p>
<p>All labs can be found here: <a href="https://github.com/ssamot/ce888/tree/master/labs/" class="uri">https://github.com/ssamot/ce888/tree/master/labs/</a></p>
<p><a id="lab1"></a></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab1">Lab 1: VM setup and simple emotion detection</a></li>
</ol>
<p><a id="lab2"></a></p>
<ol start="2" style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab2">Lab 2: Creating plots, overleaf and confidence bounds</a></li>
</ol>
<p><a id="lab3"></a></p>
<ol start="3" style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab3">Lab 3: Jupiter/IPython and Classification</a></li>
</ol>
<p><a id="lab4"></a></p>
<ol start="4" style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab4">Lab 4: Bandits and time series plotting</a></li>
</ol>
<p><a id="lab5"></a></p>
<ol start="4" style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab5">Lab 5: Recommender systems and jokes</a></li>
</ol>
<p><a id="lab6"></a></p>
<ol start="4" style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab6">Lab 6: Recommender systems and jokes</a></li>
</ol>
<h3 id="ides">IDEs</h3>
<p>You can use whatever IDE you want for the course, however my proposal would be to use PyCharm - which is installed in the lab machines:</p>
<ul>
<li><a href="https://www.jetbrains.com/pycharm/">PyCharm</a></li>
</ul>
<h3 id="assessment">Assessment</h3>
<p>The objective of the module and the main assignment is to produce a Data Science app (i.e. make use of data to generate results, make inferences, present the results to third parties) and write down the description of the methods and the results in a scientific paper. Some ideas for possible apps are provided <a href="#assignment-suggestions">here</a>.</p>
<ul>
<li>Assigments
<ul>
<li><a href="./assignments/ce888-assignment-1.pdf">Assignment 1</a></li>
</ul></li>
</ul>
<p>See FASER for exact assignment deadlines.</p>
<h3 id="readings">Readings</h3>
<p>Every lecture will come with a set of online reading suggestions - they will be added here.</p>
<p><strong>Lecture 1</strong></p>
<p><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf">Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning. Vol. 1. Springer, Berlin: Springer series in statistics, 2001.</a></p>
<p><a href="http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726%20">Breiman, Leo. &quot;Statistical modeling: The two cultures (with comments and a rejoinder by the author).&quot; Statistical Science 16.3 (2001): 199-231.</a></p>
<p><a href="https://www.tkm.kit.edu/downloads/TKM1_2011_more_is_different_PWA.pdf">Anderson, Philip W. &quot;More is different.&quot; Science 177.4047 (1972): 393-396.</a></p>
<p><strong>Lecture 2</strong></p>
<p><a href="http://cds.cern.ch/record/526679/files/0412042312_TOC.pdf">Efron, Bradley, and Robert J. Tibshirani. An introduction to the bootstrap. CRC press, 1994.</a></p>
<p><a href="http://www.haas.berkeley.edu/groups/online_marketing/facultyCV/papers/nelson_false-positive.pdf">Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. &quot;False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant.&quot; Psychological science 22.11 (2011): 1359-1366.</a></p>
<p><a href="htps://www.jstor.org/stable/2685796">Schenker, Nathaniel, and Jane F. Gentleman. &quot;On judging the significance of differences by examining the overlap between confidence intervals.&quot; The American Statistician 55.3 (2001): 182-186.</a></p>
<p><strong>Lecture 3</strong></p>
<p><a href="https://github.com/jakevdp/PythonDataScienceHandbook">Jake VanderPlas, Python Data Science Handbook Essential Tools for Working with Data 2016. O'Reilly Media, 2016</a></p>
<p><a href="https://pdfs.semanticscholar.org/0be0/d781305750b37acb35fa187febd8db67bfcc.pdf">Kohavi, Ron. &quot;A study of cross-validation and bootstrap for accuracy estimation and model selection.&quot; IJCAI. Vol. 14. No. 2. 1995.</a></p>
<p><a href="https://stuff.mit.edu/afs/athena.mit.edu/course/6/6.435/www/Geman92.pdf">Geman, Stuart, Elie Bienenstock, and René Doursat. &quot;Neural networks and the bias/variance dilemma.&quot; Neural computation 4.1 (1992): 1-58.</a></p>
<p><a href="http://scikit-learn.org/">scikit-learn's website</a></p>
<p><strong>Lecture 4</strong></p>
<p><a href="http://shop.oreilly.com/product/0636920027393.do">White, John. Bandit algorithms for website optimization. &quot; O'Reilly Media, Inc.&quot;, 2012.</a></p>
<p><a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20050239012.pdf">Oza, Nikunj C. &quot;Online bagging and boosting.&quot; Systems, man and cybernetics, 2005 IEEE international conference on. Vol. 3. IEEE, 2005.</a></p>
<p><a href="http://papers.nips.cc/paper/6500-deep-exploration-via-bootstrapped-dqn.pdf">Osband, Ian, et al. &quot;Deep exploration via bootstrapped DQN.&quot; Advances In Neural Information Processing Systems. 2016.</a></p>
<p><strong>Lecture 5</strong></p>
<p><a href="http://sifter.org/~simon/journal/20061211.html">Simon Funk, Netflix Update: Try This at Home</a></p>
<p><a href="https://arxiv.org/pdf/1603.04259.pdf">Barkan, Oren, and Noam Koenigstein. &quot;Item2vec: neural item embedding for collaborative filtering.&quot; Machine Learning for Signal Processing (MLSP), 2016 IEEE 26th International Workshop on. IEEE, 2016.</a></p>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.5120&amp;rep=rep1&amp;type=pdf">Hu, Yifan, Yehuda Koren, and Chris Volinsky. &quot;Collaborative filtering for implicit feedback datasets.&quot; Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. Ieee, 2008.</a></p>
<p><strong>Lecture 6</strong></p>
<p>[Rousseeuw, Peter J. &quot;Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.&quot; Journal of computational and applied mathematics 20 (1987): 53-65.][http://www.sciencedirect.com/science/article/pii/0377042787901257] <a href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">Arthur, David, and Sergei Vassilvitskii. &quot;k-means++: The advantages of careful seeding.&quot; Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics, 2007.</a></p>
<h3 id="people">People</h3>
<ul>
<li>Module Supervisor: <em>Spyros Samothrakis</em>, <script type="text/javascript">
<!--
h='&#x65;&#x73;&#x73;&#x65;&#120;&#46;&#x61;&#x63;&#46;&#x75;&#x6b;';a='&#64;';n='&#x73;&#x73;&#x61;&#x6d;&#x6f;&#116;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'" clas'+'s="em' + 'ail">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#x73;&#x73;&#x61;&#x6d;&#x6f;&#116;&#32;&#x61;&#116;&#32;&#x65;&#x73;&#x73;&#x65;&#120;&#32;&#100;&#x6f;&#116;&#32;&#x61;&#x63;&#32;&#100;&#x6f;&#116;&#32;&#x75;&#x6b;</noscript></li>
</ul>
<hr />
<hr />
<h1 id="assignment-suggestions">Assignment Suggestions</h1>
<p>Below you will find a list of potential projects suitable for CE888. Each project has a number of core references and a data source that you should read and evaluate. Your goal should be to identify a project that should both align nicely with your personal interests and qualifies as &quot;data science-y&quot; enough to be considered appropriate for the module. The write-up of your project would need to follow the template of a relevant conference or journal paper and the focus should be on quality rather than quantity. A minimum of amount of novelty is expected at each project and toy problems are not acceptable - if you help deciding on which project to work, please talk to the module supervisor.</p>
<h3 id="role-playing-games-systems-and-statistics.">Role Playing Games: systems and statistics.</h3>
<p>A massive number of gaming systems has been proposed that range from the heavy dice pools of Shadowrun and World of Darkness to the percentile system of Eclipse Phase and Call of Cthulhu. The goal of the project is to analyse the statistical qualities of these games systems (means, medians, standard errors, variances, roll distributions etc. ) and identify possible &quot;black spots&quot; in game design (e.g. do we get games with heavy tailed distributions? Do the mechanics of most games fail to correctly simulate certain events?)</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://julian.togelius.com/Isaksen2016Characterising.pdf">Isaksen, Aaron, et al. &quot;Characterising Score Distributions in Dice Games.&quot; Game and Puzzle Design Journal, 2016</a></li>
<li><a href="http://rpg-design.wikidot.com/evaluation">A Treatise on Different Dice-rolling Mechanics in RPGs</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> gapdjournal.com</p>
<p><strong>Example Data:</strong> You would need to have an interest and understanding of Role Playing Games so as to be able to at least appreciate major game systems.</p>
<hr />
<h3 id="intransitivities">Intransitivities</h3>
<p>It is often the case that we would like to organise tournaments where players of the same or similar skill are matched to one another. A phenomenon that has been observed in artificial systems is the intransitivity of skill between players. For example, let us assume that player A beats player B and that player B beats player C - one would normally conclude that A beats C. However this might not be the case, as certain qualities of player C might make it extremely advantageous against player A. The aim of this project is to identify how often intransitivities occur in real computer (or otherwise) games between players and if persistent intransitivities tell us anything about the structure of a game and the players that play it.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://ieeexplore.ieee.org/document/6242396/">Samothrakis, Spyridon, et al. &quot;Coevolving game-playing agents: Measuring performance and intransitivities.&quot; IEEE Transactions on Evolutionary Computation 17.2 (2013): 213-226.</a></li>
<li><a href="http://www.glicko.net/research/acjpaper.pdf">Glickman, Mark E. &quot;A comprehensive guide to chess ratings.&quot; American Chess Journal 3 (1995): 59-102.</a></li>
<li><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_688.pdf">Herbrich, Ralf, Tom Minka, and Thore Graepel. &quot;Trueskill™: A Bayesian skill rating system.&quot; Advances in neural information processing systems. 2006.</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE CIG</p>
<p><strong>Example Data:</strong> <a href="https://www.kaggle.com/devinanzelmo/dota-2-matches">Dota 2 Matches</a>.</p>
<hr />
<h3 id="rl-and-interpretability">RL and Interpretability</h3>
<p>Modern Reinforcement Learning helps agents learn how to act using complex patterns of text, sound and video and it's slowly moving away from research and making inroads to traditional industries (e.g., creating game NPC characters). The high dimensionality of the input space makes it however very hard to interpret why an agent preferred one action over another. In this project we will try to transfer some novel methods from supervised learning to Reinforcement Learning in order to interpret why agents make certain decisions. We will use already existing Atari game playing agents and try to interpret their actions profile in real time, effectively &quot;seeing&quot; through the agent's eyes.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/pdf/1602.04938v3">Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;&quot; Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier.&quot; KDD (2016).</a></li>
<li><a href="http://zacklipton.com/media/papers/mythos_model_interpretability_lipton2016.pdf">Lipton, Zachary C., et al. &quot;The Mythos of Model Interpretability.&quot; IEEE Spectrum (2016)</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE CIG/TCAIG/Neural Networks</p>
<p><strong>Example Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/ppwwyyxx/tensorpack/tree/master/examples/OpenAIGym">Example Open AI gym Atari Controllers</a></li>
<li><a href="https://github.com/marcotcr/lime">Lime</a></li>
<li><a href="https://gym.openai.com/evaluations/eval_L55gczPrQJamMGihq9tzA">Example Open AI agent playing breakout</a></li>
</ol>
<hr />
<h3 id="head-bootstrap-vs-dropout">Head bootstrap vs Dropout</h3>
<p>Dropout is a well understood method for regularising neural networks. Outside neural networks, a framework commonly used for achieving similar (but not quite the same) results is &quot;bagging&quot;. Unfortunately, one has to train multiple neural networks in order to gain the advantages of bagging, a process that is very slow. Recently, in the context of Reinforcement Learning, an algorithm has been proposed where multiple output layers of a neural network are trained in parallel using bootstrapping, while the core network remains the same. This project will evaluate this configuration in supervised learning problems.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://arxiv.org/pdf/1602.04621">Osband, Ian, et al. &quot;Deep Exploration via Bootstrapped DQN.&quot; arXiv preprint arXiv:1602.04621 (2016).</a></li>
<li><a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py">Single estimator versus bagging: bias-variance decomposition</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier">The Bagging Classifier</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Neural Networks and Learning Systems</p>
<p><strong>Example Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py">Example MNIST MLP for Keras</a></li>
<li><a href="https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py">Example CIFAR-10 for Keras</a></li>
</ol>
<hr />
<h3 id="cause-and-effect">Cause and effect</h3>
<p>Understanding cause from effect in pairs of data is of paramount importance; for example one might want to understand if the raise in height is causing a drop in temperature or the other way around. This project will try to learn the causal direction of cause-effect pairs using recurrent neural networks. Data is presented as a set of collected datapoints (not a sequence, but we will treat it is us such) of various lengths and recurrent neural network should be trained to infer the causal direction of the data.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/">Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras</a></li>
<li><a href="https://arxiv.org/pdf/1412.3773v3.pdf">Distinguishing cause from effect using observational data: methods and benchmarks</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Knowledge and Data Engineering</p>
<p><strong>Example Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://webdav.tuebingen.mpg.de/cause-effect/">Cause and effect pairs</a></li>
<li><a href="http://webdav.tuebingen.mpg.de/cause-effect/pairs_1.0.zip">Cause and effect pairs file to be used in experiments</a></li>
</ol>
<hr />
<h3 id="bootstrapping-for-polling">Bootstrapping for polling</h3>
<p>It has been hypothesised that recent (repeated) poll failures have to do with three key assumptions a) that the &quot;undecided&quot; crowd will invariably move towards the status quo b) that voters are not lying on purpose or out of fear c) that no section of the demographic is completely missing from the poll. This project will try to align polling results with demographic data using a biased version of bootstrapping, where one should try to re-sample (and thus present to a learning algorithm) sampling points according to how often we assume they occur in the general population.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://ieeexplore.ieee.org/document/1571498/">Online Bagging and Boosting</a></li>
<li><a href="http://www.scholarpedia.org/article/Similarity_measures">Similarity Measures</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Knowledge and Data Engineering</p>
<p><strong>Example Data:</strong> Identify an event of interest to you (e.g. elections) and find polling data from it, preferably ones that have the demographic characteristics of the people polled.</p>
<hr />
<h3 id="artificial-intelligence-and-society">Artificial Intelligence and society</h3>
<p>There is an active debate on what the impact of the raise of artificial intelligence will be on labour and labour time. One could possibly use data from previous industrial revolutions and try to make a coherent argument on whether labour hours will go up or down as a result of improved machinery (i.e. intelligent machines). This is a &quot;small data&quot; project and methods tailored to smaller datasets should be used - examples in the references below.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://xa.yimg.com/kq/groups/20503014/322130564/name/ch3.pdf">Joy, Bill. &quot;Why the future doesn’t need us.&quot; Nanoethics. The Ethical and Social Implications of Nanotechnology (2000): 17-30.</a></li>
<li><a href="http://groups.csail.mit.edu/mac/users/rauch/worktime/hours_workweek.html">Pre-industrial workers had a shorter workweek than today's</a></li>
<li><a href="http://scikit-learn.org/stable/auto_examples/gaussian_process/plot_compare_gpr_krr.html">Example of time series analysis</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> Journal of Artificial Intelligence Research, AI and Society track</p>
<p><strong>Example Data:</strong> See the second reference above, but also you probably need to discover data online.</p>
<hr />
<h3 id="question-answering-using-random-forests">Question Answering using Random Forests</h3>
<p>Random Forests are a machine learning method that is trivially parallelisable and extremely fast to train. With the advent of word2vec, one has a mechanism that can extract the semantic meaning of words directly, by having them converted into vector representations. For this project we will use random forests directly on word2vec sequences on the bABi tasks, a set of question answering tasks for Artificial Intelligence. You will not need to actually use any word2vec method for this project, just to convert tasks sentences to fixed length representations of vectors and feed them to a Random Forest.</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/pdf/1502.05698v10">Weston, Jason, et al. &quot;Towards ai-complete question answering: A set of prerequisite toy tasks.&quot; arXiv preprint arXiv:1502.05698 (2015).</a></li>
<li><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Mikolov, Tomas, et al. &quot;Distributed representations of words and phrases and their compositionality.&quot; Advances in neural information processing systems. 2013.</a></li>
</ol>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Knowledge and Data Engineering</p>
<p><strong>Example Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz">bAbi Tasks</a></li>
<li><a href="http://nlp.stanford.edu/projects/glove/">Glove Vectors</a></li>
</ol>
<hr />
<hr />
            </div>
    </div>
  </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>